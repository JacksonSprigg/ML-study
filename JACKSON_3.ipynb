{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "\n",
    "Welcome to your third lab! This notebook contains all the code and comments that you need to submit. Labs are two weeks long and the places where you need to edit are highlighted in red. Feel free to add in your own markdown for additional comments.\n",
    "\n",
    "__Submission details: make sure you have run all your cells from top to bottom (you can click _Kernel_ and _Restart Kernel and Run All Cells_). Submit this Jupyter Notebook and also submit the .py file that is generated.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code snippet does not need to be edited\n",
    "\n",
    "from python_environment_check import check_packages\n",
    "from python_environment_check import set_background\n",
    "\n",
    "## Colour schemes for setting background colour\n",
    "white_bgd = 'rgba(0,0,0,0)'\n",
    "red_bgd = 'rgba(255,0,0,0.2)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Code snippets in red (similar to this) is where you need to edit your answer)\n",
    "# Set your student ID and name here:\n",
    "\n",
    "student_number = 31491162  # 12345678\n",
    "student_name = \"Jackson Sprigg\" # \"John Doe\"\n",
    "\n",
    "set_background(red_bgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you are going to do in this lab exercise!\n",
    "\n",
    "In this laboratory exercise, you will create algorithms to train non-linear models using MLPs. \n",
    "\n",
    "In all of the tasks below, you should use PyTorch Lightning to design, train and test MLP models. You can use any pre-written libraries like matplotlib, pandas and numpy to visualize your results. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "- **Section 1** :  Approximate the sine function.\n",
    "- **Section 2** : Design a shallow MLP for the fashion MNIST\n",
    "- **Section 3** : Comparing the performance of Shallow MLP vs Deep MLP.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Approximate the sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-4b571e33a677>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-4b571e33a677>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <div class=\"alert alert-block alert-info\">\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## What you should do in this task!\n",
    "\n",
    "In this section, we will approximate the sine function with a neural network to get a sense of how architecture and hyperparameters affect neural network performance. \n",
    "    \n",
    "#### In this task, you will work on the following points:\n",
    " 1. As the first step you should have PyTorch and PyTorch-Lightning installed in your local machine. We have given you the set of necessary libraries and details on PyTorch functionalities that you need to use when implementing algorithm for Task 1. The first sub task is to create your custom dataset using PyTorch datasets and dataloaders.\n",
    "    \n",
    " 2. Define the custom dataset class (i.e., Train and Test datasets) and visualize the train dataset you've created.\n",
    "    \n",
    " 3. Design the Shallow Linear MLP model using PyTorch Lightning Module.\n",
    "    \n",
    " 4. Train and evaluate the MLP model on defined train dataset and test dataset.\n",
    "    \n",
    " 5. Visualize experimental results using Matplotlib.\n",
    "\n",
    "\n",
    "Before approaching, we will be introducing Pytorch Lightning Neural Network structure, Pytorch datasets, dataloaders and optimizers.\n",
    "\n",
    "<img src=\"./figures/sine_wave.gif\" width=\"1200\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch & PyTorch-Lightning Installation\n",
    "\n",
    "What are the differences between PyTorch and PyTorch-Lightning?\n",
    "\n",
    "PyTorch is based on the Torch library, adapted for Python. PyTorch is a deep learning library that allows you to have greater control of your neural network architecture, and have a lot more customisable hyper parameters / functions (such as the loss function etc.) compared to other deep learning frameworks such as TensorFlow / Keras.\n",
    "\n",
    "PyTorch-Lightning is a higher level of PyTorch, meaning that it is easier to use and run models on compared to the original PyTorch. There are methods that are already built into the classes for PyTorch-Lightning which you don't have to worry about as much, and takes away a lot of the additional considerations such as passing your dataset via CUDA, hence PyTorch-Lightning code will look simpler than PyTorch!\n",
    "\n",
    "As the first step we import all the necessary libraries needed to implement these lab tasks. \n",
    "\n",
    "Note: Do not modify seed values or use any other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Installing collected packages: PyYAML\n",
      "Successfully installed PyYAML-6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.5 requires pathlib, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "# If you run on Jupyter Lab uncomment bellow comment\n",
    "! pip install --quiet \"matplotlib\" \"pytorch-lightning\" \"pandas\" \"torchmetrics\" \n",
    "! pip install --ignore-installed \"PyYAML\" --user\n",
    "#! pip install --user \"PyYAML\"\n",
    "\n",
    "# If you run on google colab uncomment bellow comment\n",
    "#! pip install --quiet \"matplotlib\" \"pytorch-lightning\" \"pandas\" \"torchmetrics\"\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# For reproducability\n",
    "torch.manual_seed(1234)\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define GPU number\n",
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Pytorch Datasets and Dataloaders </h2>\n",
    "\n",
    "Pytorch has a huge number of functionalities that make training our neural networks very easy! One of those functionalities is the Pytorch dataset and dataloader (they are real life-savers!). In depth review on PyTorch Datasets and Dataloaders are covered in Lectures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load datasets, we will use torchvision module and to create a dataloader, we will use sub module of torch as follows.\n",
    "\n",
    "**from torch.utils.data import DataLoader**\n",
    "\n",
    "Under torchvision datasets you can find popular datasets that are frequently used for machine learning/deep learning tasks (eg., MNIST, SVHN, CIFAR10, CIFAR100 etc). You can create your own custom dataset using torchvision dataset in built functionalities and in this task we will show how to load custom datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating a Pytorch dataset\n",
    "\n",
    "The dataset you are going to be creating will be points from a \"noisy\" sine wave. To create the custom dataset, you can use PyTorch dataset inbuilt functionalities. <br>\n",
    "\n",
    "\n",
    "The Pytorch dataset class has three essential parts:<br>\n",
    "1. The \\__init__ function (as most Python classes do)<br>\n",
    "2. The \\__getitem__ function (this is called during every iteration)<br>\n",
    "3. The \\__len__ function (this must return the length of the dataset)\n",
    "\n",
    "**Remember! The \"self\" within classes will become attributes of that class that you can use within other methods that are defined for that class. If you defined an attribute without self.<\\name>, then that attribute cannot be used for other methods.**\n",
    "\n",
    "Make sure to follow all inline comments specified for each code fragment that you need to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Create a \"SineDataset\" class by importing the Pytorch Dataset class\n",
    "\n",
    "class SineDataset(Dataset):\n",
    "    \"\"\" Data noisy sinewave dataset\n",
    "        num_datapoints - the number of datapoints you want\n",
    "    \"\"\"\n",
    "    def __init__(self, num_datapoints):\n",
    "        # Lets generate the noisy sinewave points\n",
    "        \n",
    "        # Create \"num_datapoints\" worth of random x points using a uniform distribution (0-1) using torch.rand\n",
    "        # Then scale and shift the points to be between -9 and 9\n",
    "        self.x_data = torch.randn(num_datapoints)*9-9\n",
    "        \n",
    "        # Calculate the sin of all data points in the x vector and the scale amplitude\n",
    "        # Scale the amplitude by diving by 2.5\n",
    "        self.y_data = torch.sin(self.x_data)/2.5\n",
    "        \n",
    "        # Add some gaussein noise to each datapoint using torch.randn_like\n",
    "        # Note:torch.randn_like will generate a tensor of gaussein noise the same size \n",
    "        # and type as the provided tensor\n",
    "        # Divide the randomly generated values by 20 (so it is less noisy)\n",
    "        self.y_data += torch.randn_like(self.y_data)/20\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # This function is called by the dataLOADER class whenever it wants a new mini-batch\n",
    "        # The dataLOADER class will pass the dataSET and number of datapoint indexes (mini-batch of indexes)\n",
    "        # It is up to the dataSET's __getitem__ function to output the corresponding input datapoints \n",
    "        # AND the corresponding labels\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "        # Note:Pytorch will actually pass the __getitem__ function one index at a time\n",
    "        # If you use multiple dataLOADER \"workers\" multiple __getitem__ calls will be made in parallel\n",
    "        # (Pytorch will spawn multiple threads)\n",
    "\n",
    "    def __len__(self):\n",
    "        # We also need to specify a \"length\" function, Python will use this fuction whenever\n",
    "        # You use the Python len(function)\n",
    "        # We need to define it so the dataLOADER knows how big the dataSET is!\n",
    "        return self.x_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4439, -2.5211, -2.1644, -4.2202, -3.1955, -2.4982, -5.0257, -5.7295])\n",
      "tensor([ 0.7442, -0.5814, -0.8289,  0.8813,  0.0539, -0.5999,  0.9513,  0.5258])\n",
      "tensor([ 1.8434,  0.6588, -0.2349, -0.0306,  1.7462, -0.0722, -1.6794, -1.7010])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(8)*9-9\n",
    "print(x)\n",
    "print(torch.sin(x))\n",
    "print(torch.randn_like(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create instances from defined custom dataset and visualize the training dataset\n",
    "\n",
    "Now that you've defined your dataset, lets create an instance of it for training and testing and then create dataloaders to make it easy to iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "n_x_train = 30000   # the number of training datapoints\n",
    "n_x_test = 8000     # the number of testing datapoints\n",
    "BATCH_SIZE = 16     # the batch size for task 1\n",
    "\n",
    "# Create an instance of the SineDataset for both the training and test set \n",
    "# (Here we have only training and test set. Therefore consider validation set also equals to test set)\n",
    "dataset_train = SineDataset(n_x_train)\n",
    "dataset_test  = SineDataset(n_x_test)\n",
    "\n",
    "# Now we need to pass the dataset to the Pytorch dataloader class along with some other arguments\n",
    "# batch_size - the size of our mini-batches\n",
    "# shuffle - whether or not we want to shuffle the dataset \n",
    "# For training shuffle is set to True and for Testing/Validation shuffle is set to False\n",
    "data_loader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "data_loader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "## Why is it neccessary for us to shuffle the training, and not shuffle validation/test?\n",
    "\n",
    "# We are training on the training, hence why it is called training. We don't want to just \"learn the order\" of the data. By shuffling we prevent this scare of overfitting\n",
    "# The validation and test doesn't matter as much because we are using it to see if the training data helped us learn about the test data at a second layer of abstraction. If we are worried about a model just \"training for the test\"\n",
    "# We have the second test set (the one after validation) that the model has to take another model of abstraction to train on. This system is substantial complex for out problems here today in a way that\n",
    "# we dont need to worry about the model training only to pass tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualise the dataset you've created!!\n",
    "\n",
    "Note: see here how we can just directly access the data from the dataset class. Make sure your generated sinewave matches the described sinewave within the dataset class!. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataSET size: 30000\n",
      "Test DataSET size: 8000\n",
      "Train DataLOADER size: 1875\n",
      "Test DataLOADER size: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training data')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Visualize dataset using matplotlib scatter plot\n",
    "\n",
    "print(\"Train DataSET size:\", len(dataset_train))\n",
    "print(\"Test DataSET size:\", len(dataset_test))\n",
    "\n",
    "print(\"Train DataLOADER size:\", len(data_loader_train))\n",
    "print(\"Test DataLOADER size:\", len(data_loader_test))\n",
    "\n",
    "plt.scatter(dataset_train.x_data, dataset_train.y_data)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Training data\")\n",
    "\n",
    "#Hovers around 0.4, so looks good to me\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's design a Neual Network and Train it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Neural Network Architecture</h2>\n",
    "\n",
    "Up until now we have only created a single linear layer with an input layer and an output layer. In this Lab you will start to create multi-layered networks with many \"hidden\" layers separated by \"activation functions\" that give our networks \"non-linearities\". If we didn't have these activation functions and simple stacked layers together, our network would be no better than a single linear layer! Why? Because multiple sequential \"linear transformations\" can be modeled with just a single linear transformation. \n",
    "\n",
    "Neural networks are associated with a Directed Acyclic Graphs (DAG) describing how the functions are composed together. For example, we might have three functions $f^{(1)}, f^{(2)}$, and $f^{(3)}$, connected in a chain, to form in a chain, to form  $f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x))).$ In this case, $f^{(1)}$ is called the first layer of the network, $f^{(2)}$ is called the second layer, and so on.  The ﬁnal layer of a feedforward network is called the output layer.\n",
    "\n",
    "Except the output layer, the behavior of the other layers is not directly speciﬁed by the training data. The learning algorithm must decide how to use those layers to produce the desired output, but the training data do not say what each individual layer should do. Instead, the learning algorithm must decide how to use these layers to best implement an approximation of $f^*$. Because the training data does not show the desired output for each of these layers, and they\n",
    "are called hidden layers. These hidden layers, receive input from many other units and computes its own activation value. This requires us to choose the activation functions that will be used to compute the hidden layer values.\n",
    "\n",
    "So what are these nonlinear activation functions that turn our simple linear models into a power \"nonlinear function approximator\"? Some common examples are:<br>\n",
    "1. relu\n",
    "2. sigmoid\n",
    "3. tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pytorch Lightning Module</h3>\n",
    "\n",
    "Now we can define a Pytorch Lightning model to be trained!<br>\n",
    "To do so, here you need to use the Pytorch LightningModule class as the base for defining your network. Just like the dataset class, this class has a number of important functions.\n",
    "A LightningModule is a PyTorch nn.Module and it has a few more helpful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import display\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "#from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "#from pytorch_lightning.loggers import CSVLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from IPython.display import clear_output\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from torchmetrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Design the Shallow Linear MLP model using PyTorch Lightning Module\n",
    "\n",
    "Design a two layer Shallow MLP model and train it with both SGD and Adam optimizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "class ShallowLinear(LightningModule):\n",
    "    def __init__(self, hidden_size=[1, 64, 1], learning_rate=1e-2, optimizer=\"SGD\"):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes, you can look at the PDF for the info\n",
    "        self.learning_rate = learning_rate # Learning rate\n",
    "        self.loss_fn = torch.nn.MSELoss() # Use MSE loss as cost function\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate) # Optimizer\n",
    "        # self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        D_in, H, D_out = data_loader_train[0], hidden_sizes[0], data_loader_train[0]\n",
    "        \n",
    "        self.linear1 = nn.Linear(D_in, H) \n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "        self.test_accuracy = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # This function is an important one and we must create it or pytorch will give us an error!\n",
    "        # This function defines the \"forward pass\" of our neural network\n",
    "        \n",
    "        #Lets define the sqeuence of events for our forward pass!\n",
    "        x = x.reshape(x.shape[0], -1) # hidden layer\n",
    "        x = F.tanh(self.linear1(x)) # activation function --> use tanh\n",
    "\n",
    "        #No activation function on the output!!\n",
    "        x = self.linear2(x) # output layer\n",
    "        \n",
    "        #Note we re-use the variable x as we don't care about overwriting it \n",
    "        #though in later labs we will want to use earlier hidden layers\n",
    "        #later in our network!\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Write training step\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        \n",
    "        preds = logits.argmax(1)\n",
    "        self.train_accuracy.update(preds, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_acc\", self.train_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Write validation step\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        \n",
    "        preds = logits.argmax(1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Write testing step\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        \n",
    "        preds = logits.argmax(1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "        \n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # Write predict step\n",
    "        return\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Return Adam or SGD optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return data_loader_train\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return data_loader_test\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return data_loader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Define training and testing methods for models\n",
    "\n",
    "By using the Trainer Constructor you can train and test the model.\n",
    "Also Trainer will automatically enables: \n",
    "1. Tensorboard logging \n",
    "2. Model checkpointing \n",
    "3. Training and validation loop \n",
    "4. early-stopping\n",
    "\n",
    "In this task, we will test the model performance for both optimizers:\n",
    "- SGD\n",
    "- ADAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'TQDMProgressBar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-87b63b8858d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdevices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# limiting got iPython runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTQDMProgressBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefresh_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCSVLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logs_task1_SGD/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TQDMProgressBar' is not defined"
     ]
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Initialize Model with SGD optimizer\n",
    "model_sgd = \"SGD\"\n",
    "\n",
    "# Train model for 20 epochs\n",
    "trainer_task1_SGD = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    max_epochs=20,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    "    logger=CSVLogger(save_dir=\"logs_task1_SGD/\"),\n",
    ")\n",
    "trainer_task1_SGD.fit(model_sgd)\n",
    "\n",
    "# Evaluate Model\n",
    "trainer_task1_SGD.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "\n",
    "[{'test_loss': 0.009513414464890957}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Initialize Model with Adam optimizer\n",
    "model_adam = ???\n",
    "\n",
    "# Train model for 20 epochs\n",
    "trainer_task1_ADAM = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    max_epochs=20,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    "    logger=CSVLogger(save_dir=\"logs_task1_Adam/\"),\n",
    ")\n",
    "trainer_task1_ADAM.fit(model_adam)\n",
    "\n",
    "# Evaluate Model\n",
    "trainer_task1_ADAM.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "\n",
    "[{'test_loss': 0.005056165624409914}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Generate scatter plots for above two trained models to compare noisy datapoints and denoised predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Scatter plot for model trained using SGD (call predict function)\n",
    "predictions_sgd = ???\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Scatter plot for model trained using Adam (call predict function)\n",
    "predictions_adam = ??? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Visualize experimental results\n",
    "\n",
    "Pytorch-lightning module has its own built in methods to log values. These log files can be then used to visualize experimental results. You can use python plotting libraries such as matplotlib.\n",
    "\n",
    "Using those logs, plot train losses for models trained on SGD and Adam.\n",
    "\n",
    "Note: Make sure to drop NaN entries from dataframes before you plot using matplotlib.\n",
    "\n",
    "You can read the logs by using the pandas library (pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# read logs for model trained with SGD\n",
    "\n",
    "\n",
    "# read logs for model trained with Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Visualize train losses for model trained with SGD and Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Analysing above results, what optimizer you will choose? Explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Discuss why this simple shallow network is able to denoise noisy data and approximate sine function ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 & 3 : Compare Shallow MLP and Deep MLP\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## What you should do these sections 2 and 3!!\n",
    "\n",
    "In sections 2 and 3 you will be training a Shallow MLPs and Deep MLPs for classifying images on the data file \"section2_data.npz\" which is the Fashion-MNIST dataset that contains images and labels for training, validation and test purposes (The images are 28x28 grayscale images).\n",
    "\n",
    "You have to use Pytorch inbuilt datasets, Pytorch Lightning module class to construct a MLP in order to perform training and testing on the given datasets using stochastic gradient descent (SGD).\n",
    "    \n",
    "#### In you will work on the following points:\n",
    " 1. Create training, validation and testing dataloaders.\n",
    " 2. Visualize training datasets.\n",
    " 3. Design shallow neural network model.\n",
    " 4. Perform training the model and evaluation for different settings. Report test accuracies.\n",
    " 5. Visualize experimental results for training losses.\n",
    " 6. Visualize experimental results for validation accuracies.\n",
    " 7. Visualize predictions.\n",
    " 8. Optimize Shallow network's performance.\n",
    "    \n",
    "    \n",
    "#### In section 3 you will work on the following points:\n",
    " 1. Design deep neural network model.\n",
    " 2. Perform training the model and evaluation for different settings. Report test accuracies.\n",
    " 3. Visualize experimental results for training loss vs Validation accuracy.\n",
    " 4. Visualize predictions.\n",
    " 5. Discussion on experimental results.\n",
    "\n",
    "<img src=\"figures/shallow_deep_mlp.png\" width=\"1200\" align=\"center\">\n",
    "    \n",
    "In the above figure A is a shallow neural network and B is a deep neural network.\n",
    "    \n",
    "Note:  In all the parts below, you should only use the training images and their labels to train your model. You may use the **validation set** to pick a trained model. For example, during training, you can test the accuracy of your model using the validation set every epoch and pick the model that achieves the highest validation accuracy. You should then report your results on the test set once you choose your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create custom dataloader\n",
    "\n",
    "The following class reads the data for section 2 & 3 tasks and creates a torch dataset object for it. With this, you can easily \n",
    "use a dataloader to train your model. \n",
    "\n",
    "Note: Make sure that the file \"section2_data.npz\" is located properly (in this example, it should be in the same folder as this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# For reproducability\n",
    "torch.manual_seed(1234)\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "BATCH_SIZE = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "class Section3Data(Dataset):\n",
    "    def __init__(self, trn_val_tst = 0):\n",
    "        # Load numpy data\n",
    "        data = ???\n",
    "        if trn_val_tst == 0:\n",
    "            # Create dataset for trainloader --> images arr_0, labels arr_1\n",
    "            self.images = ???\n",
    "            self.labels = ???\n",
    "        elif trn_val_tst == 1:\n",
    "            # Create dataset for valloader --> images arr_2, labels arr_3\n",
    "            self.images = ???\n",
    "            self.labels = ???\n",
    "        else:\n",
    "            # Create dataset for testloader --> images arr_4, labels arr_5\n",
    "            self.images = ???\n",
    "            self.labels = ???\n",
    "            \n",
    "        # Normalize images [0,1]  \n",
    "        self.images = ???\n",
    "\n",
    "    # Define len function\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # Define getitem function\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "   \n",
    "        sample = self.images[idx,:]\n",
    "        labels = self.labels[idx]\n",
    "        return sample, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using dataset class create a dataloader for the section 3 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Call training dataset and create the trainloader\n",
    "trainset = ???\n",
    "trainloader = ???\n",
    "\n",
    "# Call validation dataset and create the trainloader\n",
    "valset = ???  \n",
    "valloader = ???\n",
    "\n",
    "# Call testing dataset and create the trainloader\n",
    "testset = ???  \n",
    "testloader = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualize dataset\n",
    "\n",
    "Lets visualise that mini-batches that the training dataloader gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "\n",
    "# We can create an iterater using the dataloaders and take a random sample \n",
    "\n",
    "\n",
    "# visualize dataset using torchvision grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Design Shallow MLP\n",
    "\n",
    "Design a Shallow MLP with one hidden linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "class Shallow_MLP(LightningModule):\n",
    "    def __init__(self, n, learning_rate=1e-1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = ???\n",
    "        self.loss_fun = ??? # Use CE loss\n",
    "        \n",
    "        self.linear1 =  ???\n",
    "        self.linear2 =  ???\n",
    "        \n",
    "        self.train_accuracy = Accuracy()\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        #Pass input through conv layers\n",
    "        \n",
    "        out1 = ???\n",
    "        out2 = ???\n",
    "    \n",
    "        return out2\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Write training step\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Write validation step\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Write testing step\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # Write predict step\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return valloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train and evaluate model's performance for following scenarios\n",
    "\n",
    "a. fc1 : Linear(784 $\\times$ 32) $\\rightarrow$ ReLU $\\rightarrow$ fc2 : Linear(32 x$\\times$ 10)\n",
    "\n",
    "b. fc1 : Linear(784 $\\times$ 128) $\\rightarrow$ ReLU $\\rightarrow$ fc2 : Linear(128 $\\times$ 10)\n",
    "\n",
    "c. fc1 : Linear(784 $\\times$ 512) $\\rightarrow$ ReLU $\\rightarrow$ fc2 : Linear(512 $\\times$ 10)\n",
    "\n",
    "In all the parts above, you should only use the training images and their labels to train your model. You may use the validation set to pick a trained model.\n",
    "\n",
    "For example, during training, you can test the accuracy of your model using the validation set every epoch and pick the model that achieves the highest validation accuracy. You should then report your results on the test set once you choose your model. \n",
    "\n",
    "Note: Make sure to have different log file directories and checkpoint folders (eg: logs_task_2a, logs_task_2b and logs_task_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Initialize Shallow MLP model with n = 32\n",
    "model = ???\n",
    "\n",
    "# Define checkpoint callback function to save best model\n",
    "checkpoint_callback_2a = ???\n",
    "\n",
    "# Train and test the model\n",
    "trainer_2a = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  \n",
    "    max_epochs=100,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback_2a],\n",
    "    logger=CSVLogger(save_dir=\"logs_task_2a/\"),\n",
    ")\n",
    "trainer_2a.fit(model)\n",
    "trainer_2a.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "\n",
    "[{'test_loss': 0.4268353581428528, 'test_acc': 0.8521000146865845}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Initialize Shallow MLP model with n = 128\n",
    "model = ???\n",
    "\n",
    "# Define checkpoint callback function to save best model\n",
    "checkpoint_callback_2b = ???\n",
    "\n",
    "# Train and test the model\n",
    "trainer_2b = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  \n",
    "    max_epochs=100,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20),checkpoint_callback_2b],\n",
    "    logger=CSVLogger(save_dir=\"logs_task_2b/\"),\n",
    ")\n",
    "trainer_2b.fit(model)\n",
    "trainer_2b.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "    \n",
    "[{'test_loss': 0.4281507730484009, 'test_acc': 0.8611000180244446}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Initialize Shallow MLP model with n = 512\n",
    "model = ???\n",
    "\n",
    "# Define checkpoint callback function to save best model\n",
    "checkpoint_callback_2c = ???\n",
    "\n",
    "# Train and test the model\n",
    "trainer_2c = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None, \n",
    "    max_epochs=100,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback_2c],\n",
    "    logger=CSVLogger(save_dir=\"logs_task_2c/\"),\n",
    ")\n",
    "trainer_2c.fit(model)\n",
    "trainer_2c.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "    \n",
    "[{'test_loss': 0.4100257456302643, 'test_acc': 0.8678666949272156}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Plot Training losses for the different shallow networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "\n",
    "# read logs for 2a\n",
    "\n",
    "# read logs for 2b\n",
    "\n",
    "# read logs for 2c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Plot using matplotlib\n",
    "\n",
    "\n",
    "# Discuss what you see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Plot Validation accuracies for the different shallow networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Plot using matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Visualize 5 predictions of test set along with groundtruths and input images for 3rd Shallow MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Generate predictions using predict function\n",
    "\n",
    "\n",
    "# visualize predictions along with ground truths and input images using matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Optimize hyper-parameters to improve accuracy of shallow network\n",
    "\n",
    "What do you recommend to improve shallow network's accuracy further ?\n",
    "\n",
    "- Make sure to test at least 2-3 hyper parameters\n",
    "- For each hyper parameter, have 3 variations\n",
    "- Plot out the results after you train + tested it. It is recommended to use subplot (or overlay onto 1 plot the accuracies for each model). **Important! Think about which accuracy is most relevant** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# What do you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the Shallow MLP model using above suggested. When testing different hyper-parameters, you can use the original shallow MLP class from earlier, and just train using the different hyper-parameters. Save your MLP with the optimized parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Create New Class\n",
    "# class Shallow_MLP_Optimized(LightningModule):\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Test the model\n",
    "\n",
    "# Visualize accuracy graphs and compare it with 2.3 Accuracies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Deep MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Design Deep MLP\n",
    "\n",
    "Design a Deep MLP with four linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "\n",
    "class Deep_MLP(LightningModule):\n",
    "    def __init__(self, n1, n2, n3, learning_rate=1e-1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = ???\n",
    "        self.loss_fun = ??? # Use CE loss\n",
    "        \n",
    "        self.linear1 =  ???\n",
    "        self.linear2 =  ???\n",
    "        self.linear3 =  ???\n",
    "        self.linear4 =  ???\n",
    "        \n",
    "        self.train_accuracy = Accuracy()\n",
    "        self.val_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        #Pass input through conv layers\n",
    "        \n",
    "        out1 = ??? \n",
    "        out2 = ???\n",
    "        out3 = ???\n",
    "        out4 = ???\n",
    "      \n",
    "        return out4\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Write training step\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Write validation step\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Write testing step\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # Write predict step\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return valloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train and evaluate model's performance for following scenarios\n",
    "\n",
    "a. fc1 : Linear(784 $\\times$ 128) $\\rightarrow$ ReLU $\\rightarrow$ fc2 : Linear(128 $\\times$ 64) $\\rightarrow$ ReLU $\\rightarrow$ fc3 : Linear(64 $\\times$ 32) ->$\\rightarrow$ Relu $\\rightarrow$ fc4 : Linear(32 $\\times$ 10)\n",
    "\n",
    "b. fc1 : Linear(784 $\\times$ 32) $\\rightarrow$ ReLU $\\rightarrow$ fc2 : Linear(32 $\\times$ 64) $\\rightarrow$ ReLU $\\rightarrow$ fc3 : Linear(64 $\\times$ 128) $\\rightarrow$ Relu $\\rightarrow$ fc4 : Linear(128 $\\times$ 10)\n",
    "\n",
    "c. fc1 : Linear(784 $\\times$ 64) $\\rightarrow$ ReLU $\\rightarrow$ fc2 : Linear(64 $\\times$ 64) $\\rightarrow$ ReLU $\\rightarrow$ fc3 : Linear(64 $\\times$ 64) $\\rightarrow$ Relu $\\rightarrow$ fc4 : Linear(64 $\\times$ 10)\n",
    "\n",
    "Note: Make sure to have different log file directories (eg: logs_task_3a, logs_task_3b and logs_task_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "\n",
    "# Initialize Deep MLP model for scenario 3a\n",
    "model = ???\n",
    "\n",
    "# Define checkpoint callback function to save best model\n",
    "checkpoint_callback_3a = ???\n",
    "\n",
    "# Train and Test Model\n",
    "trainer_3a = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  \n",
    "    max_epochs=100,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback_3a],\n",
    "    logger=CSVLogger(save_dir=\"logs_task_3a/\"),\n",
    ")\n",
    "trainer_3a.fit(model)\n",
    "trainer_3a.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "\n",
    "[{'test_loss': 0.4924968481063843, 'test_acc': 0.8584499955177307}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Initialize Deep MLP model for scenario 3b\n",
    "model = ???\n",
    "\n",
    "# Define checkpoint callback function to save best model\n",
    "checkpoint_callback_3b = ???\n",
    "\n",
    "# Train and Test Model\n",
    "trainer_3b = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  \n",
    "    max_epochs=100,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback_3b],\n",
    "    logger=CSVLogger(save_dir=\"logs_task_3b/\"),\n",
    ")\n",
    "trainer_3b.fit(model)\n",
    "trainer_3b.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "    \n",
    "[{'test_loss': 0.4536038041114807, 'test_acc': 0.8570333123207092}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize Deep MLP model for scenario 4c\n",
    "model = ???\n",
    "\n",
    "# Define checkpoint callback function to save best model\n",
    "checkpoint_callback_3c = ???\n",
    "\n",
    "# Train and Test Model\n",
    "trainer_3c = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    max_epochs=100,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback_3c],\n",
    "    logger=CSVLogger(save_dir=\"logs_task_3c/\"),\n",
    ")\n",
    "trainer_3c.fit(model)\n",
    "trainer_3c.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should obtain a printed output similar to this:\n",
    "    \n",
    "[{'test_loss': 0.40754958987236023, 'test_acc': 0.8532999753952026}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Plot Training loss vs Validation loss for the different deep networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "\n",
    "# read logs for 3a\n",
    "\n",
    "# read logs for 3b\n",
    "\n",
    "# read logs for 3c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='rgba(255,0,0,0.2)';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Plot using matplotlib, you can overlay the graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualize 5 predictions of test set along with groundtruths and input images for 3rd Deep MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Generate predictions using predict function\n",
    "\n",
    "\n",
    "# visualize predictions along with ground truths and input images using matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Discussion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Question: Did you observe a strange behaviour for the deep MLPs? If yes, what is that ? Discuss what might be the source of that.\n",
    "\n",
    "# Answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_background(red_bgd)\n",
    "\n",
    "# Question: How does the deep MLP compare with the shallow MLP for this case?\n",
    "\n",
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not remove or edit the following code snippet. \n",
    "\n",
    "When submitting your report, please ensure that you have run the entire notebook from top to bottom. You can do this by clicking \"Kernel\" and \"Restart Kernel and Run All Cells\". Make sure the last cell (below) has also been run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = str(student_number) + 'Lab_3_Student'\n",
    "cmd = \"jupyter nbconvert --to script Lab_3_Student.ipynb --output \" + file_name\n",
    "if(os.system(cmd)):\n",
    "    print(\"Error converting to .py\")\n",
    "    print(\"cmd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "# <center> That is all for this Lab!\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
